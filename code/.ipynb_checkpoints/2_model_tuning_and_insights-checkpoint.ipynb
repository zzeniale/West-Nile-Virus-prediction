{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: West Nile Virus Classification\n",
    "---\n",
    "    Chenyze | Elaine | Kenrick | Raphael\n",
    "    \n",
    "---\n",
    "Project notebook organisation:<br>\n",
    "[1 - Exploratory Data Analysis and Feature Engineering](./1_eda_and_feature_engineering.ipynb)<br>\n",
    "**2 - Model Tuning and Insights** (current notebook)<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preparing-Data\" data-toc-modified-id=\"Preparing-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preparing Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reading-pickle\" data-toc-modified-id=\"Reading-pickle-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Reading pickle</a></span></li><li><span><a href=\"#Cleaning-up-data\" data-toc-modified-id=\"Cleaning-up-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Cleaning up data</a></span></li></ul></li><li><span><a href=\"#Dictionaries-to-call-for-modelling\" data-toc-modified-id=\"Dictionaries-to-call-for-modelling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dictionaries to call for modelling</a></span></li><li><span><a href=\"#RUNNING-MODEL-AND-PICKLING-IT\" data-toc-modified-id=\"RUNNING-MODEL-AND-PICKLING-IT-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>RUNNING MODEL AND PICKLING IT</a></span></li><li><span><a href=\"#Cost-Benefit-Analysis\" data-toc-modified-id=\"Cost-Benefit-Analysis-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Cost-Benefit Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cost\" data-toc-modified-id=\"Cost-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Cost</a></span></li><li><span><a href=\"#Benefit\" data-toc-modified-id=\"Benefit-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Benefit</a></span></li><li><span><a href=\"#Effectiveness-of-spraying-efforts-thus-far\" data-toc-modified-id=\"Effectiveness-of-spraying-efforts-thus-far-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Effectiveness of spraying efforts thus far</a></span></li><li><span><a href=\"#Conclusions\" data-toc-modified-id=\"Conclusions-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Conclusions</a></span></li></ul></li><li><span><a href=\"#Conclusion-and-Recommendations\" data-toc-modified-id=\"Conclusion-and-Recommendations-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Conclusion and Recommendations</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing essential libraries for data cleaning and EDA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for handling date time\n",
    "import datetime as dt\n",
    "\n",
    "# stats and other libraries\n",
    "import scipy.stats as stats\n",
    "\n",
    "# plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# for handling geographic data\n",
    "\n",
    "# modeling libraries\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from matplotlib_venn import venn2\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import featuretools as ft\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "sns.set_style('ticks')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.read_pickle('./assets/processed.zip')\n",
    "df_dict = df_processed.to_dict()\n",
    "\n",
    "test = pd.read_csv('./assets/test.csv', parse_dates=['Date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_dict.keys():\n",
    "    df_dict[i]['train'] = df_dict[i]['train'].drop(columns = 'Species_UNSPECIFIED CULEX')\n",
    "    df_dict[i]['test'] = df_dict[i]['test'].drop(columns = ['Species_UNSPECIFIED CULEX', 'WnvPresent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = {}\n",
    "X_test = {}\n",
    "y_train = {}\n",
    "y_test = {}\n",
    "X_all = {}\n",
    "y_all = {}\n",
    "test_all = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to populate dictionaries of X and Y training and test sets,\n",
    "\n",
    "for i in df_dict.keys():\n",
    "    X_train[i], X_test[i], y_train[i], y_test[i] = \\\n",
    "    train_test_split(df_dict[i]['train'].drop(columns = 'WnvPresent'), df_dict[i]['train']['WnvPresent'], \\\n",
    "                     test_size = 0.25, stratify = df_dict[i]['train']['WnvPresent'], random_state = 42)\n",
    "    X_all[i] = df_dict[i]['train'].drop(columns = 'WnvPresent')\n",
    "    y_all[i] = df_dict[i]['train']['WnvPresent']\n",
    "    test_all[i] = df_dict[i]['test']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries to call for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining dictionary of pipeline transformers and classifiers\n",
    "\n",
    "pipe_dict = {'ss' : ('ss', StandardScaler()),\n",
    "             'lr' : ('lr', LogisticRegression()),\n",
    "             'knn' : ('knn', KNeighborsClassifier()),\n",
    "             'dt' : ('dt', DecisionTreeClassifier()),\n",
    "             'rf' : ('rf', RandomForestClassifier()),\n",
    "             'et' : ('et', ExtraTreesClassifier()),\n",
    "             'xgc' : ('xgc', xgb.XGBClassifier(scale_pos_weight = 19, seed = 42)),\n",
    "            }\n",
    "\n",
    "\n",
    "# Defining dictionary of parameters for pipeline transformers\n",
    "\n",
    "param_dict = {'lr_params' : {'lr__penalty' : ['l1', 'l2'],\n",
    "                             'lr__solver' : ['liblinear'],\n",
    "                             'lr__C' : np.logspace(-5, 0, 100),\n",
    "                             'lr__class_weight' : ['balanced']\n",
    "                            }, \\\n",
    "              'knn_params' : {'knn__n_neighbors' : [1, 3, 5, 7, 15],\n",
    "                              'knn__weights':['uniform','distance'],\n",
    "                              'knn__metric':['euclidean','manhattan']\n",
    "                             }, \\\n",
    "              'dt_params' : {'dt__max_depth': [2, 3, 5, 7, 10],\n",
    "                             'dt__min_samples_split': [5, 10, 15, 20],\n",
    "                             'dt__min_samples_leaf': [2, 3, 4, 5, 6, 7],\n",
    "                             'dt__class_weight' : ['balanced'],\n",
    "\n",
    "                            }, \\\n",
    "              'rf_params' : {'rf__n_estimators': [10, 20, 50, 100, 150, 200],\n",
    "                             'rf__max_depth': [5, 10, 15, 20, 25],\n",
    "                             'rf__min_samples_leaf': [2, 5, 10],\n",
    "                             'rf__class_weight' : ['balanced', 'balanced_subsample']\n",
    "                            }, \\\n",
    "              'et_params' : {'et__n_estimators': [10, 20, 50, 100, 150, 200],\n",
    "                             'et__max_depth': [2, 3, 4, 5, 10, 20],\n",
    "                             'et__min_samples_leaf': [2, 5, 10],\n",
    "                             'et__class_weight' : ['balanced', 'balanced_subsample'],\n",
    "                            }, \\\n",
    "#               'xgc_params' : {'dt__max_depth': [2, 3, 5, 7, 10],\n",
    "#                              'dt__min_samples_split': [5, 10, 15, 20],\n",
    "#                              'dt__min_samples_leaf': [2, 3, 4, 5, 6, 7]\n",
    "#                              }, \\\n",
    "#               'xgc_params' : {'xgc__eval_metric' : ['auc'],\n",
    "#                               'xgc__objective' : ['binary:logistic'],\n",
    "#                               'xgc__scale_pos_weight': [19],\n",
    "#                               'xgc__subsample' : [0.3, 0.5, 0.7],\n",
    "#                               'xgc__colsample_bytree' : [0.3, 0.5, 0.7],\n",
    "#                               'xgc__learning_rate' : [0.05, 0.10],\n",
    "#                               'xgc__max_depth' : [2, 3, 5],\n",
    "#                               'xgc__n_estimators' : [500, 1000, 1500],\n",
    "#                                   'xgc__reg_alpha' : [0, 1, 5],\n",
    "#                                   'xgc__reg_lambda' : [1, 2, 3, 4, 5],\n",
    "#                                   'xgc__gamma' : [0.01, 0.1, 0.25],\n",
    "#                                  }, \\\n",
    "\n",
    "             }\n",
    "\n",
    "param_no_tuning = {'lr_params' : {},\\\n",
    "                   'knn_params' : {},\\\n",
    "                   'dt_params' : {},\\\n",
    "                   'rf_params' : {},\\\n",
    "                   'et_params' : {},\\\n",
    "                   'xgc_params' : {},\\\n",
    "                   'lr_params' : {}\n",
    "                  }\n",
    "\n",
    "param_tuning_reg = {'lr_params' : {},\\\n",
    "                   'knn_params' : {},\\\n",
    "                   'dt_params' : {},\\\n",
    "                   'rf_params' : {},\\\n",
    "                   'et_params' : {},\\\n",
    "                   'xgc_params' : {},\\\n",
    "                   'lr_params' : {}\n",
    "                  }\n",
    "\n",
    "\n",
    "\n",
    "# Defining dictionary of more descriptive names for pipeline transformers and classifiers\n",
    "\n",
    "pipe_dict_names = {'ss' : 'Standard Scaler',\n",
    "                   'lr' : 'Logistic Regression',\n",
    "                   'knn' : 'K Nearest Neighbors',\n",
    "                   'dt' : 'Decision Tree',\n",
    "                   'et' : 'Extra Trees',\n",
    "                   'rf' : 'Random Forest',\n",
    "                   'xgc' : 'XGBoost',\n",
    "                  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to run pipeline model for each set of X stored in X_dict above and populate model_dict with model \\\n",
    "# parameters and results\n",
    "\n",
    "def model_making(X_dict, scaler, classifier, model_dict, param_dict):\n",
    "    for i in df_dict.keys():\n",
    "        # Defining model_name to be used as key for model_dict\n",
    "        model_name = '_'.join([classifier, str(i)])\n",
    "        \n",
    "        # Initialising empty dictionary (within the model_dict dictionary) to store instanced model parameters and results\n",
    "        model_dict[model_name] = {}\n",
    "        \n",
    "        if scaler == None:\n",
    "            model_dict[model_name]['name'] = ' '.join([pipe_dict_names[classifier], df_dict[i]['name']])\n",
    "            model_dict[model_name]['pipe'] = Pipeline([pipe_dict[classifier]])\n",
    "        else:\n",
    "            model_dict[model_name]['name'] = ' '.join([pipe_dict_names[classifier], df_dict[i]['name'], pipe_dict_names[scaler]])\n",
    "            model_dict[model_name]['pipe'] = Pipeline([pipe_dict[scaler], pipe_dict[classifier]])            \n",
    "        \n",
    "        \n",
    "        model_dict[model_name]['params'] = param_dict[classifier + '_params'].copy()\n",
    "\n",
    "        \n",
    "        # Defining vectoriser parameter grid for model instance\n",
    "\n",
    "        # Defining model for GridSearchCV using above pipeline and parameters\n",
    "        model_dict[model_name]['model'] = GridSearchCV(model_dict[model_name]['pipe'], \\\n",
    "                                                       param_grid = model_dict[model_name]['params'],\n",
    "                                                       cv = 3,\n",
    "                                                       verbose = 1,\n",
    "                                                       scoring = 'roc_auc',\n",
    "                                                       n_jobs = 8)\n",
    "\n",
    "        # Fitting model for GridSearchCV\n",
    "        model_dict[model_name]['model'].fit(X_train[i], y_train[i])\n",
    "        \n",
    "        # Storing cross-validation scores and best parameters for model instance\n",
    "        model_dict[model_name]['train_score'] = model_dict[model_name]['model'].best_score_ \n",
    "        model_dict[model_name]['best_params'] = model_dict[model_name]['model'].best_params_\n",
    "        model_dict[model_name]['test_score'] = roc_auc_score(y_test[i], [prob[1] for prob in model_dict[model_name]['model'].best_estimator_.predict_proba(X_test[i])])\n",
    "        model_dict[model_name]['confusion_matrix'] = pd.DataFrame(confusion_matrix(y_test[i],\\\n",
    "                                                                                   model_dict[model_name]['model'].\n",
    "                                                                                   best_estimator_.predict(X_test[i])), \\\n",
    "                                                                  index = ['Actual WNV absent','Actual WNV present'],\n",
    "                                                                  columns = ['predicted WNV absent', 'predicted WNV present'])\n",
    "        # Storing predict_probability from best scoring model instance\n",
    "        model_dict[model_name]['best_model'] = model_dict[model_name]['model'].best_estimator_.fit(X_all[i], y_all[i])\n",
    "        model_dict[model_name]['train_pred_proba'] = [i[1] for i in model_dict[model_name]['best_model'].predict_proba(X_all[i])]\n",
    "        model_dict[model_name]['train_pred_df'] = pd.DataFrame({'True_Values' : y_all[i],\n",
    "                                                                'Pred_Probs' : model_dict[model_name]['train_pred_proba']})\n",
    "\n",
    "        model_dict[model_name]['test_pred_proba'] = [i[1] for i in model_dict[model_name]['best_model'].predict_proba(test_all[i])]\n",
    "\n",
    "\n",
    "            \n",
    "        # Printing scores and best parameters for model instance\n",
    "        print(model_dict[model_name]['name'], '\\n')\n",
    "        print(f'Score on Train Set:', model_dict[model_name]['train_score'])\n",
    "        print(f'Best Parameters:', model_dict[model_name]['best_params'])\n",
    "        print(f'Score on Test Set:', model_dict[model_name]['test_score'])\n",
    "        print(model_dict[model_name]['confusion_matrix'], f'\\n\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_tuning = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Rolling 10 days Standard Scaler \n",
      "\n",
      "Score on Train Set: 0.7787730769397748\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.776672431160876\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   2489                      0\n",
      "Actual WNV present                   138                      0 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Rolling 14 days Standard Scaler \n",
      "\n",
      "Score on Train Set: 0.7763094380290411\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.7765501540109817\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   2489                      0\n",
      "Actual WNV present                   138                      0 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Rolling 18 days Standard Scaler \n",
      "\n",
      "Score on Train Set: 0.7822119253993277\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.7831036269731748\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   2489                      0\n",
      "Actual WNV present                   138                      0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_making(df_dict, 'ss', 'lr', model_no_tuning, param_no_tuning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Rolling 10 days Standard Scaler \n",
      "\n",
      "Score on Train Set: 0.6539481702213693\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.6910449455866682\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   2469                     20\n",
      "Actual WNV present                   131                      7 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-847e429042b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_making\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'knn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_no_tuning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_no_tuning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-1f727842a460>\u001b[0m in \u001b[0;36mmodel_making\u001b[1;34m(X_dict, scaler, classifier, model_dict, param_dict)\u001b[0m\n\u001b[0;32m     48\u001b[0m                                                                 'Pred_Probs' : model_dict[model_name]['train_pred_proba']})\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mmodel_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_pred_proba'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'best_model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    472\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_final_estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 delayed_query(\n\u001b[0;32m    453\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 454\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m             )\n\u001b[0;32m    456\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, data, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \"\"\"\n\u001b[1;32m--> 291\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_making(df_dict, 'ss', 'knn', model_no_tuning, param_no_tuning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Rolling 10 days \n",
      "\n",
      "Score on Train Set: 0.6086546035539488\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.5978129858333188\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   2400                     89\n",
      "Actual WNV present                   121                     17 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Rolling 14 days \n",
      "\n",
      "Score on Train Set: 0.6168031922466012\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.6131587681450557\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   2410                     79\n",
      "Actual WNV present                   116                     22 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Rolling 18 days \n",
      "\n",
      "Score on Train Set: 0.6144195984125821\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.6084743887598186\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   2408                     81\n",
      "Actual WNV present                   118                     20 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_making(df_dict, None, 'dt', model_no_tuning, param_no_tuning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Rolling 10 days \n",
      "\n",
      "Score on Train Set: 0.7004673520847958\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.6608439452431277\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   2452                     37\n",
      "Actual WNV present                   127                     11 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Rolling 14 days \n",
      "\n",
      "Score on Train Set: 0.6940014722920368\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.6862601242568751\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   2451                     38\n",
      "Actual WNV present                   127                     11 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Rolling 18 days \n",
      "\n",
      "Score on Train Set: 0.6900682748007114\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.6784402093850624\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   2455                     34\n",
      "Actual WNV present                   124                     14 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_making(df_dict, None, 'et', model_no_tuning, param_no_tuning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Rolling 10 days \n",
      "\n",
      "Score on Train Set: 0.7166459317572165\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.7138074193116379\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   2455                     34\n",
      "Actual WNV present                   124                     14 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Rolling 14 days \n",
      "\n",
      "Score on Train Set: 0.712737829950049\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.7173272544121672\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   2451                     38\n",
      "Actual WNV present                   124                     14 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Rolling 18 days \n",
      "\n",
      "Score on Train Set: 0.7303666981518532\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.7029218416103318\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   2447                     42\n",
      "Actual WNV present                   123                     15 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_making(df_dict, None, 'rf', model_no_tuning, param_no_tuning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Rolling 10 days \n",
      "\n",
      "Score on Train Set: 0.8365894074163807\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.8345168014626676\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   1837                    652\n",
      "Actual WNV present                    33                    105 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Rolling 14 days \n",
      "\n",
      "Score on Train Set: 0.8355804078017162\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.8331440948870683\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   1858                    631\n",
      "Actual WNV present                    35                    103 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Rolling 18 days \n",
      "\n",
      "Score on Train Set: 0.8341216501905979\n",
      "Best Parameters: {}\n",
      "Score on Test Set: 0.8340771859951904\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   1827                    662\n",
      "Actual WNV present                    33                    105 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_making(df_dict, None, 'xgc', model_no_tuning, param_no_tuning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model_no_tuning['xgc_1']['test_pred_proba']\n",
    "\n",
    "output = pd.DataFrame(zip(test['Id'], predict), columns = ['Id', 'WnvPresent'])\n",
    "\n",
    "output.to_csv('./datasets/YOLO_20191107_2123_xgc_00_10_sum_precip-sunlight_w-clusters_no_tuning.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUNNING MODEL AND PICKLING IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising empty dictionary to store model data\n",
    "\n",
    "model_dict = {}\n",
    "\n",
    "#model_dict_reg = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  88 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done 541 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=8)]: Done 600 out of 600 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Rolling 10 days Standard Scaler \n",
      "\n",
      "Score on Train Set: 0.7898941417726049\n",
      "Best Parameters: {'lr__C': 0.8902150854450392, 'lr__class_weight': 'balanced', 'lr__penalty': 'l1', 'lr__solver': 'liblinear'}\n",
      "Score on Test Set: 0.7876686405692293\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   1739                    750\n",
      "Actual WNV present                    35                    103 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  88 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done 536 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=8)]: Done 600 out of 600 | elapsed:   58.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Rolling 14 days Standard Scaler \n",
      "\n",
      "Score on Train Set: 0.7853260612228314\n",
      "Best Parameters: {'lr__C': 0.6280291441834247, 'lr__class_weight': 'balanced', 'lr__penalty': 'l1', 'lr__solver': 'liblinear'}\n",
      "Score on Test Set: 0.787619147437129\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   1714                    775\n",
      "Actual WNV present                    36                    102 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  88 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done 535 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=8)]: Done 600 out of 600 | elapsed:   55.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Rolling 18 days Standard Scaler \n",
      "\n",
      "Score on Train Set: 0.7896449641476803\n",
      "Best Parameters: {'lr__C': 0.7924828983539169, 'lr__class_weight': 'balanced', 'lr__penalty': 'l1', 'lr__solver': 'liblinear'}\n",
      "Score on Test Set: 0.7927023832398786\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   1751                    738\n",
      "Actual WNV present                    38                    100 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_making(df_dict, 'ss', 'lr', model_dict, param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 196 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done 360 out of 360 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Rolling 10 days \n",
      "\n",
      "Score on Train Set: 0.7923319471846698\n",
      "Best Parameters: {'dt__class_weight': 'balanced', 'dt__max_depth': 5, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 5}\n",
      "Score on Test Set: 0.7953488101268771\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   1641                    848\n",
      "Actual WNV present                    21                    117 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 196 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 360 out of 360 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Rolling 14 days \n",
      "\n",
      "Score on Train Set: 0.7727286475710452\n",
      "Best Parameters: {'dt__class_weight': 'balanced', 'dt__max_depth': 5, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 5}\n",
      "Score on Test Set: 0.7935539562480712\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   1663                    826\n",
      "Actual WNV present                    24                    114 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 196 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done 360 out of 360 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Rolling 18 days \n",
      "\n",
      "Score on Train Set: 0.772631947711808\n",
      "Best Parameters: {'dt__class_weight': 'balanced', 'dt__max_depth': 5, 'dt__min_samples_leaf': 6, 'dt__min_samples_split': 10}\n",
      "Score on Test Set: 0.7954012146196889\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   1584                    905\n",
      "Actual WNV present                    24                    114 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_making(df_dict, None, 'dt', model_dict, param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 160 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done 422 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=8)]: Done 648 out of 648 | elapsed:   26.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Rolling 10 days \n",
      "\n",
      "Score on Train Set: 0.8362646889802677\n",
      "Best Parameters: {'et__class_weight': 'balanced', 'et__max_depth': 20, 'et__min_samples_leaf': 5, 'et__n_estimators': 150}\n",
      "Score on Test Set: 0.8305151361643404\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   1959                    530\n",
      "Actual WNV present                    45                     93 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 124 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=8)]: Done 370 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=8)]: Done 620 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=8)]: Done 648 out of 648 | elapsed:   27.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Rolling 14 days \n",
      "\n",
      "Score on Train Set: 0.8392848082869544\n",
      "Best Parameters: {'et__class_weight': 'balanced', 'et__max_depth': 20, 'et__min_samples_leaf': 5, 'et__n_estimators': 100}\n",
      "Score on Test Set: 0.8329868814086328\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   1988                    501\n",
      "Actual WNV present                    50                     88 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 160 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done 404 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=8)]: Done 648 out of 648 | elapsed:   27.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Rolling 18 days \n",
      "\n",
      "Score on Train Set: 0.837679439584434\n",
      "Best Parameters: {'et__class_weight': 'balanced_subsample', 'et__max_depth': 20, 'et__min_samples_leaf': 5, 'et__n_estimators': 150}\n",
      "Score on Test Set: 0.83314700624778\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   1982                    507\n",
      "Actual WNV present                    49                     89 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_making(df_dict, None, 'et', model_dict, param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 124 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=8)]: Done 324 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=8)]: Done 540 out of 540 | elapsed:   31.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Rolling 10 days \n",
      "\n",
      "Score on Train Set: 0.8434778914612783\n",
      "Best Parameters: {'rf__class_weight': 'balanced_subsample', 'rf__max_depth': 15, 'rf__min_samples_leaf': 5, 'rf__n_estimators': 20}\n",
      "Score on Test Set: 0.8224623124355861\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   2065                    424\n",
      "Actual WNV present                    55                     83 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 124 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=8)]: Done 326 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=8)]: Done 540 out of 540 | elapsed:   32.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Rolling 14 days \n",
      "\n",
      "Score on Train Set: 0.8421226568707366\n",
      "Best Parameters: {'rf__class_weight': 'balanced_subsample', 'rf__max_depth': 10, 'rf__min_samples_leaf': 2, 'rf__n_estimators': 100}\n",
      "Score on Test Set: 0.8313346842047036\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   1978                    511\n",
      "Actual WNV present                    45                     93 \n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 152 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=8)]: Done 380 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=8)]: Done 540 out of 540 | elapsed:   31.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Rolling 18 days \n",
      "\n",
      "Score on Train Set: 0.8415179658268298\n",
      "Best Parameters: {'rf__class_weight': 'balanced', 'rf__max_depth': 10, 'rf__min_samples_leaf': 2, 'rf__n_estimators': 150}\n",
      "Score on Test Set: 0.8294452111027653\n",
      "                    predicted WNV absent  predicted WNV present\n",
      "Actual WNV absent                   1976                    513\n",
      "Actual WNV present                    45                     93 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_making(df_dict, None, 'rf', model_dict, param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lr_1', 'lr_2', 'lr_3', 'dt_1', 'dt_2', 'dt_3', 'et_1', 'et_2', 'et_3', 'rf_1', 'rf_2', 'rf_3'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.DataFrame(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.to_pickle('./model_dict_20191108_0713hrs.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to plot prediction probability and ROC AUC curve\n",
    "\n",
    "# Defining function to count true positive rate\n",
    "\n",
    "def TPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_positive = df[(df[true_col] == 1) & (df[pred_prob_col] >= threshold)].shape[0]\n",
    "    false_negative = df[(df[true_col] == 1) & (df[pred_prob_col] < threshold)].shape[0]\n",
    "    return true_positive / (true_positive + false_negative)\n",
    "\n",
    "# Defining function to count false positive rate\n",
    "def FPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_negative = df[(df[true_col] == 0) & (df[pred_prob_col] <= threshold)].shape[0]\n",
    "    false_positive = df[(df[true_col] == 0) & (df[pred_prob_col] > threshold)].shape[0]\n",
    "    return 1 - (true_negative / (true_negative + false_positive))\n",
    "\n",
    "# Defining function to plot prediction probability and ROC AUC curve for selected models\n",
    "def subplot_prob_dist(model_dict, list_of_models):\n",
    "    nrows = int(np.ceil(len(list_of_models)))\n",
    "    fig, ax = plt.subplots(nrows = nrows, ncols = 2, figsize = (15, nrows * 5))\n",
    "    plt.subplots_adjust(wspace = 0.4, hspace = 0.4)\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    thresholds = np.linspace(0, 1, 200)\n",
    "\n",
    "    for i, model_name in enumerate(list_of_models):\n",
    "        pred_df = model_dict[model_name]['pred_df']\n",
    "        model_desc = model_dict[model_name]['name']\n",
    "        \n",
    "        roc_auc = roc_auc_score(pred_df['true_values'], pred_df['pred_probs'])\n",
    "        \n",
    "        try:\n",
    "            ax[(i * 2)].hist(pred_df[pred_df['true_values'] == 0]['pred_probs'], bins = 25, color = 'b', \\\n",
    "                             alpha = 0.6, label = 'Outcome = r/personalfinance')\n",
    "            ax[(i * 2)].hist(pred_df[pred_df['true_values'] == 1]['pred_probs'], bins = 25, color = 'y', \\\n",
    "                                 alpha = 0.6, label = 'Outcome = r/investing')\n",
    "            ax[(i * 2)].set_title(f'{model_desc} \\n Distribution of P(Outcome = r/investing)')\n",
    "            ax[(i * 2)].set_ylabel('Frequency')\n",
    "            ax[(i * 2)].set_xlabel('Predicted Probability that Outcome = r/investing')\n",
    "            ax[(i * 2)].legend(loc = 'upper center')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            tpr_values = [TPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "            fpr_values = [FPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    " \n",
    "            ax[(i * 2 + 1)].plot(fpr_values, tpr_values, label = 'ROC Curve', color = 'c')\n",
    "            ax[(i * 2 + 1)].plot((0, 0), (0, tpr_values[len(tpr_values) - 1]), color = 'c')\n",
    "            ax[(i * 2 + 1)].plot((fpr_values[0], 1), (1 , 1), color = 'c')\n",
    "            ax[(i * 2 + 1)].plot(thresholds, thresholds, label = 'baseline', linestyle = '--', color = 'y')\n",
    "            ax[(i * 2 + 1)].set_title(f'{model_desc}  \\n ROC AUC = {roc_auc:2f}')\n",
    "            ax[(i * 2 + 1)].set_ylabel('Sensitivity')\n",
    "            ax[(i * 2 + 1)].set_xlabel('1 - Specificity')\n",
    "            ax[(i * 2 + 1)].legend(loc = 'lower right')\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost-Benefit Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost\n",
    "The Chicago Department of Public Health (CDPH) conducts mosquito spraying as part of their measure to reduce the occurrence of WNV. The spraying is conducted from dusk to around midnight from ultra low volumn (ULV) sprayer trucks, using the chemical Zenivex E4 ([City of Chicago, 2019](https://www.chicago.gov/city/en/depts/cdph/provdrs/healthy_communities/news/2019/august/city-to-spray-insecticide-thursday-to-kill-mosquitoes.html)). This is a 4% solution of etofenprox, sprayed at 4.5 - 9 ounces per minute, at a vehicle speed of 10 - 15 mph ([Central Massachussettes Mosquito Control Project](https://www.cmmcp.org/pesticide-information/pages/zenivex-e4-etofenprox)). Assuming each truck has an area of effect of about 3 m to each side of the truck, the overall spray area is approximately **0.6 km<sup>2</sup>** per truck.\n",
    "\n",
    "The cost of Zenivex E4 is about \\$80 USD per gallon ([North Dakota Department of Health, 2013](http://www.gfmosquito.com/wp-content/uploads/2013/06/2013-North-Dakota-Bid-Tabulation.pdf)). Given the current rate of spraying and assuming a total spray duration of 5 hours, the cost of pesticides for <i>each sprayer truck</i> is <b>\\\\$843.76 - \\$1687.50 USD</b>. \n",
    "\n",
    "Given that the total area of Chicago is 606.1 km<sup>2</sup>, it would take about 1000 trucks at the same time to cover the entire area. \n",
    "\n",
    "### Benefit\n",
    "Benefits from mosquito spraying would include increased quality of life from fewer people falling sick and dying, increased workplace productivity from fewer people falling ill and going on medical leave, as well as savings in hospital expenses from treating WNV patients. Of these, only the latter two are measurable.\n",
    "\n",
    "About 1 in 5 people infected with WNV develop West Nile fever with other symptoms such as headache, body aches, joint pains, vomiting, etc. Recovery from West Nile fever takes from a few days to several weeks, and prolonged fatigue is common ([Peterson, 2019](https://www.uptodate.com/contents/west-nile-virus-infection-beyond-the-basics)). \n",
    "\n",
    "About 1 in 150 people infected develop severe neuroinvasive diseases such as encephalitis or meningitis, in which the virus travels through the blood and infects the brain and spinal cord. Recovery is prolonged and less than 40% of patients with the severe diseases recover after one year ([Peterson, 2019](https://www.uptodate.com/contents/west-nile-virus-infection-beyond-the-basics)).\n",
    "\n",
    "Given that the median household income in Chicago was \\\\$55,295 (as of 2017; [Data USA](https://datausa.io/profile/geo/chicago-il/)), one can estimate the amount of losses the city will face from an incapacitated workforce. In 2017, there were 90 WNV cases, including 8 deaths ([CBS Chicago, 2019](https://chicago.cbslocal.com/2018/08/29/west-nile-virus-death-reported-in-illinois/)). This means that approximately 18 people developed West Nile fever. Assuming all were working adults and each took two weeks off work to recover, this would have resulted in a total income loss of \\\\$19,353. On average, each WNV patient spends approximately \\\\$25,000 in the hospital. Therefore the total monetary loss caused by WNV in 2017 is approximately \\\\$488,176.\n",
    "\n",
    "### Effectiveness of spraying efforts thus far\n",
    "Based on the exploratory data analysis conducted earlier, there was a lack of evidence to support the claim that mosquito spraying had any effect on reducing the number of mosquitos. It was also revealed during earlier EDA that spraying was only done in 2011 and 2013, and mostly in September. As this is near the end of summer, breeding conditions were already becoming less favourable for mosquitos, therefore it would be difficult to discern the effects of spraying from the natural decline in mosquito populations. Further examinations of spraying efforts in 2013 August also did not reveal any noticable decrease in WNV occurrences. \n",
    "\n",
    "### Conclusions\n",
    "From the graph below, it can be seen that the money saved from reducing WNV cases would at most fund about 300 - 500 sprays. However, as the current datasets do not substantially point to a significant impact from spraying, more evidence (from a better designed spraying regime) are needed for a more concrete recommendation. For example, spraying efforts could be concentrated at the beginning of August so that there would be enough time to observe if mosquito numbers decline, in the relative absence of other confounding factors (such as temperature). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T13:19:04.368349Z",
     "start_time": "2019-11-07T13:19:03.814250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# max/optimal level of pesticide coverage\n",
    "# spraying frequency of twice a month (to cover the mosquito life cycle)\n",
    "# 1000 trucks at a time (to cover the whole Chicago)\n",
    "max_frequency = 25 * 1000\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(np.arange(1, max_frequency),\n",
    "         np.arange(1, max_frequency) * 1687.5/1000, label = 'upper cost estimate limit')\n",
    "plt.plot(np.arange(1, max_frequency),\n",
    "         np.arange(1, max_frequency) * 843.75/1000, label = 'lower cost estimate limit')\n",
    "plt.axhline(488_176/1000, color='r', linestyle=':', label = 'total loss from WNV (2017)')\n",
    "plt.title('cost vs spray frequency', fontsize=16)\n",
    "plt.xlabel('spray frequency', fontsize=14)\n",
    "plt.ylabel('cost (in 1000s)', fontsize=14)\n",
    "plt.ylim(0,2000)\n",
    "plt.xlim(0,1000)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('cost_benefit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using XGBoost (our best performing model), we achieved an ROC_AUC of **0.839** and the following confusion matrix:\n",
    "\n",
    "||predicted WNV absent|predicted WNV present|\n",
    "|---|---|---|\n",
    "|actual WNV absent|2045|444|\n",
    "|actual WNV present|54|84|\n",
    "\n",
    "Using the model, we found that WNV is more prevalent under certain conditions. **Week of year** was the top predictor by far for our model, followed by day of year, 10-days rolling sum of daylight hours, <i>Culex restuans</i>, and 10-days rolling mean of average temperature. This means that WNV is most likely to occur during certain weeks of the year (in August, as shown in the figure above), and therefore spray efforts should be concentrated during this period. Location was not a strong predictor in our model, suggesting that WNV clusters may be transient, occurring where best conditions emerge. \n",
    "\n",
    "After conducting a cost-benefit analysis, we found that the money saved from reducing WNV cases would at most fund about 300 - 500 sprays. However, as the current datasets do not substantially point to a significant impact from spraying, more evidence (from a better designed spraying regime) are needed for a more concrete recommendation. For example, spraying efforts could be concentrated at the beginning of August so that there would be enough time to observe if mosquito numbers decline, in the relative absence of other confounding factors (such as temperature). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
